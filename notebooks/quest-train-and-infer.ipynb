{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:32.360055Z",
     "iopub.status.busy": "2021-02-25T15:40:32.358090Z",
     "iopub.status.idle": "2021-02-25T15:40:32.360752Z",
     "shell.execute_reply": "2021-02-25T15:40:32.361273Z"
    },
    "papermill": {
     "duration": 0.028491,
     "end_time": "2021-02-25T15:40:32.361442",
     "exception": false,
     "start_time": "2021-02-25T15:40:32.332951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/kaggle/input/quest-with-5gkf/train_with_GKF.csv'\n",
    "TEST_PATH = '/kaggle/input/google-quest-challenge/test.csv'\n",
    "SAMPSUB_PATH = '/kaggle/input/google-quest-challenge/sample_submission.csv'\n",
    "SUB_PATH = '/kaggle/working/submission.csv'\n",
    "CKPT_PATH = '/kaggle/input/questnb-outputs/kaggle-infer2-epoch-04-val_spearman-0.38628863974944133-fold-0.ckpt'\n",
    "BERT_PATH = '/kaggle/input/questnb-outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:32.402942Z",
     "iopub.status.busy": "2021-02-25T15:40:32.402125Z",
     "iopub.status.idle": "2021-02-25T15:40:43.640005Z",
     "shell.execute_reply": "2021-02-25T15:40:43.639118Z"
    },
    "papermill": {
     "duration": 11.261404,
     "end_time": "2021-02-25T15:40:43.640127",
     "exception": false,
     "start_time": "2021-02-25T15:40:32.378723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import pytorch_lightning as pl\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:43.680246Z",
     "iopub.status.busy": "2021-02-25T15:40:43.679391Z",
     "iopub.status.idle": "2021-02-25T15:40:43.682479Z",
     "shell.execute_reply": "2021-02-25T15:40:43.681927Z"
    },
    "papermill": {
     "duration": 0.024859,
     "end_time": "2021-02-25T15:40:43.682583",
     "exception": false,
     "start_time": "2021-02-25T15:40:43.657724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:43.754491Z",
     "iopub.status.busy": "2021-02-25T15:40:43.736187Z",
     "iopub.status.idle": "2021-02-25T15:40:43.757140Z",
     "shell.execute_reply": "2021-02-25T15:40:43.756618Z"
    },
    "papermill": {
     "duration": 0.057082,
     "end_time": "2021-02-25T15:40:43.757243",
     "exception": false,
     "start_time": "2021-02-25T15:40:43.700161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ROOT_DIR = Path(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "class qDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "        qtitle,\n",
    "        qbody,\n",
    "        answer,\n",
    "        target=None,\n",
    "    ):\n",
    "        self.hparams = args\n",
    "        self.qtitle = qtitle\n",
    "        self.qbody = qbody\n",
    "        self.answer = answer\n",
    "        if target is None:\n",
    "            self.target = [0] * len(self.qtitle)\n",
    "        else:\n",
    "            self.target = target\n",
    "        self.tokenizer = transformers.BertTokenizer.from_pretrained(BERT_PATH)\n",
    "        self.maxlen = self.hparams.maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.qtitle)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(\"idx: \", idx)\n",
    "        qtitle = self.qtitle[idx]\n",
    "        qbody = self.qbody[idx]\n",
    "        answer = self.answer[idx]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            \" \".join(qtitle.split()) + \" \" + \" \".join(qbody.split()),\n",
    "            \" \".join(answer.split()),\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.maxlen,\n",
    "        )\n",
    "        return {\n",
    "            \"ids_seq\": torch.tensor(inputs[\"input_ids\"], dtype=torch.long),\n",
    "            \"attn_masks\": torch.tensor(inputs[\"attention_mask\"], dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long),\n",
    "            \"target\": torch.tensor(self.target[idx], dtype=torch.float),\n",
    "        }\n",
    "\n",
    "\n",
    "TARGET_COLUMNS= [\n",
    "    \"question_asker_intent_understanding\",\n",
    "    \"question_body_critical\",\n",
    "    \"question_conversational\",\n",
    "    \"question_expect_short_answer\",\n",
    "    \"question_fact_seeking\",\n",
    "    \"question_has_commonly_accepted_answer\",\n",
    "    \"question_interestingness_others\",\n",
    "    \"question_interestingness_self\",\n",
    "    \"question_multi_intent\",\n",
    "    \"question_not_really_a_question\",\n",
    "    \"question_opinion_seeking\",\n",
    "    \"question_type_choice\",\n",
    "    \"question_type_compare\",\n",
    "    \"question_type_consequence\",\n",
    "    \"question_type_definition\",\n",
    "    \"question_type_entity\",\n",
    "    \"question_type_instructions\",\n",
    "    \"question_type_procedure\",\n",
    "    \"question_type_reason_explanation\",\n",
    "    \"question_type_spelling\",\n",
    "    \"question_well_written\",\n",
    "    \"answer_helpful\",\n",
    "    \"answer_level_of_information\",\n",
    "    \"answer_plausible\",\n",
    "    \"answer_relevance\",\n",
    "    \"answer_satisfaction\",\n",
    "    \"answer_type_instructions\",\n",
    "    \"answer_type_procedure\",\n",
    "    \"answer_type_reason_explanation\",\n",
    "    \"answer_well_written\",\n",
    "]\n",
    "\n",
    "\n",
    "class QuestData(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, args, target_cols=TARGET_COLUMNS):\n",
    "        super().__init__()\n",
    "        self.hparams = args\n",
    "        self.target_cols = target_cols\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        df = pd.read_csv(TRAIN_PATH).fillna(\"none\")\n",
    "        df = df.loc[df[\"fold\"] != self.hparams.fold]\n",
    "        \n",
    "        qtitle = df.loc[:, \"question_title\"].values\n",
    "        qbody = df.loc[:, \"question_body\"].values\n",
    "        answer = df.loc[:, \"answer\"].values\n",
    "        target = df.loc[:, self.target_cols].values\n",
    "\n",
    "        ds = qDataset(self.hparams ,qtitle, qbody, answer, target)\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            ds,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            drop_last=True,\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        df = pd.read_csv(TRAIN_PATH).fillna(\"none\")\n",
    "        df = df.loc[df[\"fold\"] == self.hparams.fold]\n",
    "        \n",
    "        qtitle = df.loc[:, \"question_title\"].values\n",
    "        qbody = df.loc[:, \"question_body\"].values\n",
    "        answer = df.loc[:, \"answer\"].values\n",
    "        target = df.loc[:, self.target_cols].values\n",
    "\n",
    "        ds = qDataset(self.hparams ,qtitle, qbody, answer, target)\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            ds,\n",
    "            batch_size=self.hparams.batch_size*2,\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "            drop_last=True,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        df = pd.read_csv(TEST_PATH).fillna(\"none\")\n",
    "        \n",
    "        qtitle = df.loc[:, \"question_title\"].values\n",
    "        qbody = df.loc[:, \"question_body\"].values\n",
    "        answer = df.loc[:, \"answer\"].values\n",
    "        \n",
    "        ds = qDataset(self.hparams ,qtitle, qbody, answer)\n",
    "        \n",
    "        return torch.utils.data.DataLoader(\n",
    "            ds,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "            drop_last=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:43.812626Z",
     "iopub.status.busy": "2021-02-25T15:40:43.802100Z",
     "iopub.status.idle": "2021-02-25T15:40:43.832175Z",
     "shell.execute_reply": "2021-02-25T15:40:43.831638Z"
    },
    "papermill": {
     "duration": 0.0566,
     "end_time": "2021-02-25T15:40:43.832290",
     "exception": false,
     "start_time": "2021-02-25T15:40:43.775690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuestModel(pl.LightningModule):\n",
    "    def __init__(self, args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(args)\n",
    "        \n",
    "        self.bert = transformers.BertModel.from_pretrained(BERT_PATH)\n",
    "        self.bert_dropout = nn.Dropout(self.hparams.bert_dropout)\n",
    "        self.linear = nn.Linear(768, 30)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(logits, targets):\n",
    "        return nn.BCEWithLogitsLoss()(logits, targets)\n",
    "\n",
    "    def forward(self, ids_seq, attn_masks, token_type_ids):\n",
    "\n",
    "        bert_out = self.bert(\n",
    "            ids_seq, attention_mask=attn_masks, token_type_ids=token_type_ids\n",
    "        )\n",
    "        # using maxpooled output\n",
    "        max_out = self.bert_dropout(bert_out[1])\n",
    "        return self.linear(max_out)\n",
    "\n",
    "    def shared_step(self, batch):\n",
    "        ids_seq, attn_masks, token_type_ids, target = (\n",
    "            batch[\"ids_seq\"],\n",
    "            batch[\"attn_masks\"],\n",
    "            batch[\"token_type_ids\"],\n",
    "            batch[\"target\"],\n",
    "        )\n",
    "        logits = self(ids_seq, attn_masks, token_type_ids)\n",
    "        loss = self.loss(logits, target)\n",
    "        return logits, loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits, loss = self.shared_step(batch)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=False, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits, loss = self.shared_step(batch)\n",
    "        self.log(\n",
    "            \"valid_loss\", loss, on_step=False, on_epoch=True, prog_bar=False, logger=True\n",
    "        )\n",
    "        return {\"valid_loss\": loss, \"logits\": logits, \"true_preds\": batch[\"target\"]}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ids_seq, attn_masks, token_type_ids = (\n",
    "            batch[\"ids_seq\"],\n",
    "            batch[\"attn_masks\"],\n",
    "            batch[\"token_type_ids\"],\n",
    "        )\n",
    "\n",
    "        logits = self(ids_seq, attn_masks, token_type_ids)\n",
    "        return logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        grouped_parameters = [\n",
    "            {\"params\":self.bert.parameters(), \"lr\":self.hparams.bert_lr},\n",
    "            {\"params\":self.linear.parameters(), \"lr\":self.hparams.linear_lr}\n",
    "        ]\n",
    "        optim = AdamW(grouped_parameters, lr=self.hparams.bert_lr)\n",
    "        # 4863 is total number of samples in train split\n",
    "        num_training_steps = (4863//(self.hparams.batch_size*self.hparams.accumulate_grad_batches))*self.hparams.max_epochs\n",
    "        sched = get_cosine_schedule_with_warmup(optim, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "        \n",
    "        return [optim] , [sched]\n",
    "\n",
    "    def validation_epoch_end(\n",
    "        self, validation_step_outputs\n",
    "    ):  \n",
    "        y_pred = (\n",
    "            torch.sigmoid(torch.cat([out['logits'] for out in validation_step_outputs]))\n",
    "            .to(\"cpu\")\n",
    "            .detach()\n",
    "            .numpy()\n",
    "        )\n",
    "        y_true = (\n",
    "            torch.cat([out['true_preds'] for out in validation_step_outputs]).to(\"cpu\").detach().numpy()\n",
    "        )\n",
    "\n",
    "        spearman_corr = self.spearman_metric(y_true, y_pred)\n",
    "        print(\"-\"*50, f\"\\nval_spearman: {spearman_corr}\\n\", \"-\"*50)\n",
    "        self.log(\"val_spearman\", spearman_corr, logger=True)\n",
    "        \n",
    "    def test_epoch_end(self, test_outputs):\n",
    "        test_outputs = torch.sigmoid(torch.cat(test_outputs)).to(\"cpu\").detach().numpy()\n",
    "\n",
    "        submission_df = pd.read_csv(SAMPSUB_PATH)\n",
    "        submission_df.loc[:, TARGET_COLUMNS] = test_outputs\n",
    "\n",
    "        submission_df.to_csv(\n",
    "            SUB_PATH,\n",
    "            index=False,\n",
    "        )\n",
    "        print(f\"predictions saved in file {SUB_PATH}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def spearman_metric(y_true, y_pred, return_scores=False):\n",
    "        corr = [\n",
    "            spearmanr(pred_col, target_col).correlation\n",
    "            for pred_col, target_col in zip(y_pred.T, y_true.T)\n",
    "        ]\n",
    "        if return_scores:\n",
    "            return corr\n",
    "        else:\n",
    "            return np.nanmean(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:43.881879Z",
     "iopub.status.busy": "2021-02-25T15:40:43.881106Z",
     "iopub.status.idle": "2021-02-25T15:40:43.889959Z",
     "shell.execute_reply": "2021-02-25T15:40:43.889305Z"
    },
    "papermill": {
     "duration": 0.038886,
     "end_time": "2021-02-25T15:40:43.890053",
     "exception": false,
     "start_time": "2021-02-25T15:40:43.851167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(420)\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--ckpt_folder\", default=\"models\", type=str)\n",
    "parser.add_argument(\n",
    "    \"--output_filename\", default=\"none\", type=str, help=\"regex pattern or filename\"\n",
    ")\n",
    "parser.add_argument(\"--fold\", default=0, type=int, choices=[0, 1, 2, 3, 4])\n",
    "parser.add_argument(\n",
    "    \"--gpus\",\n",
    "    default=1,\n",
    "    help=\"if value is 0 cpu will be used, if string then that gpu device will be used\",\n",
    ")\n",
    "parser.add_argument(\"--maxlen\", default=512, type=int)\n",
    "parser.add_argument(\"--bert_lr\", default=1e-5, type=int)\n",
    "parser.add_argument(\"--linear_lr\", default=5e-3, type=int)\n",
    "parser.add_argument(\"--bert_dropout\", default=0.3, type=float)\n",
    "parser.add_argument(\n",
    "    \"--bert_output_used\",\n",
    "    default=\"maxpooled\",\n",
    "    type=str,\n",
    "    choices=[\"maxpooled\", \"weighted_sum\"],\n",
    ")\n",
    "parser.add_argument(\"--batch_size\", default=8, type=int)\n",
    "parser.add_argument(\"--max_epochs\", default=5, type=int)\n",
    "parser.add_argument(\"--accumulate_grad_batches\", default=2, type=int)\n",
    "parser.add_argument(\"--model_name\", default=\"quest\", type=str)\n",
    "\n",
    "# parser = pl.Trainer.add_argparse_args(parser)\n",
    "args = parser.parse_known_args()                                                                      #parser.parse_args()\n",
    "args = args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:43.932868Z",
     "iopub.status.busy": "2021-02-25T15:40:43.932006Z",
     "iopub.status.idle": "2021-02-25T15:40:43.934577Z",
     "shell.execute_reply": "2021-02-25T15:40:43.935219Z"
    },
    "papermill": {
     "duration": 0.027025,
     "end_time": "2021-02-25T15:40:43.935360",
     "exception": false,
     "start_time": "2021-02-25T15:40:43.908335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# experimenting with different values\n",
    "# on kaggle use batch_size 16 and accumulate_grad_batches 1, uses complete resources (gpu memory = 16gb)\n",
    "\n",
    "args.fold = 0\n",
    "args.maxlen = 512\n",
    "args.batch_size=16\n",
    "args.max_epochs = 5\n",
    "args.accumulate_grad_batches = 1\n",
    "args.model_name = \"kaggle-infer3\"\n",
    "\n",
    "args.effective_batch_size = args.batch_size * args.accumulate_grad_batches\n",
    "args.log_every_n_steps = args.accumulate_grad_batches * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:43.979948Z",
     "iopub.status.busy": "2021-02-25T15:40:43.979045Z",
     "iopub.status.idle": "2021-02-25T15:40:43.981622Z",
     "shell.execute_reply": "2021-02-25T15:40:43.982276Z"
    },
    "papermill": {
     "duration": 0.028396,
     "end_time": "2021-02-25T15:40:43.982400",
     "exception": false,
     "start_time": "2021-02-25T15:40:43.954004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToggleBertBaseTraining(pl.Callback):\n",
    "    def on_train_epoch_start(self, trainer, pl_module):\n",
    "        if trainer.current_epoch == 0:\n",
    "            print(\n",
    "                f\"current_epoch is: {trainer.current_epoch} and freezing BERT layer's parameters\"\n",
    "            )\n",
    "            for p in pl_module.bert.parameters():\n",
    "                p.requires_grad = False\n",
    "        else:\n",
    "            print(\n",
    "                f\"current_epoch is: {trainer.current_epoch} and unfreezing BERT layer's parameters for training\"\n",
    "            )\n",
    "            for p in pl_module.bert.parameters():\n",
    "                p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:44.024022Z",
     "iopub.status.busy": "2021-02-25T15:40:44.023286Z",
     "iopub.status.idle": "2021-02-25T15:40:51.933891Z",
     "shell.execute_reply": "2021-02-25T15:40:51.927939Z"
    },
    "papermill": {
     "duration": 7.933963,
     "end_time": "2021-02-25T15:40:51.934149",
     "exception": false,
     "start_time": "2021-02-25T15:40:44.000186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "model = QuestModel(args)\n",
    "data = QuestData(args)\n",
    "\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:40:52.004639Z",
     "iopub.status.busy": "2021-02-25T15:40:52.003662Z",
     "iopub.status.idle": "2021-02-25T15:41:25.748833Z",
     "shell.execute_reply": "2021-02-25T15:41:25.749487Z"
    },
    "papermill": {
     "duration": 33.783169,
     "end_time": "2021-02-25T15:41:25.749656",
     "exception": false,
     "start_time": "2021-02-25T15:40:51.966487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights using pretrained weights from checkpoint file: /kaggle/input/questnb-outputs/kaggle-infer2-epoch-04-val_spearman-0.38628863974944133-fold-0.ckpt\n",
      "Starting the test loop.........\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1fb0e663cb43c8a620d29550cd3497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions saved in file /kaggle/working/submission.csv\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\n",
    "#     f\"Training model_name={args.model_name} on fold={args.fold} for max_apochs={args.max_epochs} with and effective batch_size of effective_batch_size={args.effective_batch_size}\"\n",
    "# )\n",
    "# trainer.fit(model, data)\n",
    "\n",
    "print(f\"Loading model weights using pretrained weights from checkpoint file: {CKPT_PATH}\")\n",
    "model = model.load_from_checkpoint(CKPT_PATH)\n",
    "\n",
    "print(\"Starting the test loop.........\")\n",
    "trainer.test(model, data.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:25.797286Z",
     "iopub.status.busy": "2021-02-25T15:41:25.796624Z",
     "iopub.status.idle": "2021-02-25T15:41:25.801473Z",
     "shell.execute_reply": "2021-02-25T15:41:25.800883Z"
    },
    "papermill": {
     "duration": 0.030652,
     "end_time": "2021-02-25T15:41:25.801586",
     "exception": false,
     "start_time": "2021-02-25T15:41:25.770934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:25.852385Z",
     "iopub.status.busy": "2021-02-25T15:41:25.851462Z",
     "iopub.status.idle": "2021-02-25T15:41:26.590576Z",
     "shell.execute_reply": "2021-02-25T15:41:26.589918Z"
    },
    "papermill": {
     "duration": 0.765724,
     "end_time": "2021-02-25T15:41:26.590722",
     "exception": false,
     "start_time": "2021-02-25T15:41:25.824998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf wandb lightning_logs models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:26.640676Z",
     "iopub.status.busy": "2021-02-25T15:41:26.639994Z",
     "iopub.status.idle": "2021-02-25T15:41:26.644301Z",
     "shell.execute_reply": "2021-02-25T15:41:26.643764Z"
    },
    "papermill": {
     "duration": 0.030573,
     "end_time": "2021-02-25T15:41:26.644433",
     "exception": false,
     "start_time": "2021-02-25T15:41:26.613860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "# model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:26.696461Z",
     "iopub.status.busy": "2021-02-25T15:41:26.694525Z",
     "iopub.status.idle": "2021-02-25T15:41:26.697198Z",
     "shell.execute_reply": "2021-02-25T15:41:26.697742Z"
    },
    "papermill": {
     "duration": 0.031228,
     "end_time": "2021-02-25T15:41:26.697875",
     "exception": false,
     "start_time": "2021-02-25T15:41:26.666647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outputs = []\n",
    "# for batch in tqdm(data.test_dataloader()):\n",
    "#     ids_seq, attn_masks, token_type_ids, target = (\n",
    "#         batch[\"ids_seq\"].to(device),\n",
    "#         batch[\"attn_masks\"].to(device),\n",
    "#         batch[\"token_type_ids\"].to(device),\n",
    "#         batch[\"target\"],\n",
    "#     )\n",
    "\n",
    "#     logits = model(ids_seq, attn_masks, token_type_ids)\n",
    "#     outputs.append(logits)\n",
    "\n",
    "# outputs = torch.sigmoid(torch.cat(outputs)).to(\"cpu\").detach().numpy()\n",
    "\n",
    "# submission_df = pd.read_csv(SAMPSUB_PATH)\n",
    "# submission_df.loc[:, TARGET_COLUMNS] = outputs\n",
    "\n",
    "# submission_df.to_csv(\n",
    "#     SUB_PATH,\n",
    "#     index=False,\n",
    "# )\n",
    "# print(f\"predictions saved in file {SUB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:26.745438Z",
     "iopub.status.busy": "2021-02-25T15:41:26.744825Z",
     "iopub.status.idle": "2021-02-25T15:41:26.748379Z",
     "shell.execute_reply": "2021-02-25T15:41:26.749002Z"
    },
    "papermill": {
     "duration": 0.029044,
     "end_time": "2021-02-25T15:41:26.749112",
     "exception": false,
     "start_time": "2021-02-25T15:41:26.720068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.listdir('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:26.798265Z",
     "iopub.status.busy": "2021-02-25T15:41:26.797261Z",
     "iopub.status.idle": "2021-02-25T15:41:26.799820Z",
     "shell.execute_reply": "2021-02-25T15:41:26.800394Z"
    },
    "papermill": {
     "duration": 0.029215,
     "end_time": "2021-02-25T15:41:26.800517",
     "exception": false,
     "start_time": "2021-02-25T15:41:26.771302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/arch-raven/google-quest-challenge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:26.852199Z",
     "iopub.status.busy": "2021-02-25T15:41:26.850671Z",
     "iopub.status.idle": "2021-02-25T15:41:26.853409Z",
     "shell.execute_reply": "2021-02-25T15:41:26.853921Z"
    },
    "papermill": {
     "duration": 0.029362,
     "end_time": "2021-02-25T15:41:26.854057",
     "exception": false,
     "start_time": "2021-02-25T15:41:26.824695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(\"google-quest-challenge\")\n",
    "# !git checkout \n",
    "# !pwd\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:26.903696Z",
     "iopub.status.busy": "2021-02-25T15:41:26.901857Z",
     "iopub.status.idle": "2021-02-25T15:41:26.904404Z",
     "shell.execute_reply": "2021-02-25T15:41:26.904884Z"
    },
    "papermill": {
     "duration": 0.028994,
     "end_time": "2021-02-25T15:41:26.904991",
     "exception": false,
     "start_time": "2021-02-25T15:41:26.875997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.listdir('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:26.955012Z",
     "iopub.status.busy": "2021-02-25T15:41:26.954297Z",
     "iopub.status.idle": "2021-02-25T15:41:26.958547Z",
     "shell.execute_reply": "2021-02-25T15:41:26.957966Z"
    },
    "papermill": {
     "duration": 0.030455,
     "end_time": "2021-02-25T15:41:26.958701",
     "exception": false,
     "start_time": "2021-02-25T15:41:26.928246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! python src/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:27.011423Z",
     "iopub.status.busy": "2021-02-25T15:41:27.009182Z",
     "iopub.status.idle": "2021-02-25T15:41:27.012189Z",
     "shell.execute_reply": "2021-02-25T15:41:27.012702Z"
    },
    "papermill": {
     "duration": 0.03042,
     "end_time": "2021-02-25T15:41:27.012814",
     "exception": false,
     "start_time": "2021-02-25T15:41:26.982394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! python src/main.py --fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:27.062889Z",
     "iopub.status.busy": "2021-02-25T15:41:27.062193Z",
     "iopub.status.idle": "2021-02-25T15:41:27.066586Z",
     "shell.execute_reply": "2021-02-25T15:41:27.065991Z"
    },
    "papermill": {
     "duration": 0.030648,
     "end_time": "2021-02-25T15:41:27.066734",
     "exception": false,
     "start_time": "2021-02-25T15:41:27.036086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! python src/main.py --fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:27.119051Z",
     "iopub.status.busy": "2021-02-25T15:41:27.117221Z",
     "iopub.status.idle": "2021-02-25T15:41:27.119871Z",
     "shell.execute_reply": "2021-02-25T15:41:27.120392Z"
    },
    "papermill": {
     "duration": 0.030671,
     "end_time": "2021-02-25T15:41:27.120503",
     "exception": false,
     "start_time": "2021-02-25T15:41:27.089832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! python src/main.py --fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-25T15:41:27.171597Z",
     "iopub.status.busy": "2021-02-25T15:41:27.170955Z",
     "iopub.status.idle": "2021-02-25T15:41:27.175039Z",
     "shell.execute_reply": "2021-02-25T15:41:27.175525Z"
    },
    "papermill": {
     "duration": 0.031514,
     "end_time": "2021-02-25T15:41:27.175643",
     "exception": false,
     "start_time": "2021-02-25T15:41:27.144129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! python src/main.py --fold 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 60.856796,
   "end_time": "2021-02-25T15:41:28.568249",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-25T15:40:27.711453",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3e459bee769a43c98169be6a119b9cd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77d13ba09fad4b61a6a3f51f54c8910e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "9e76ad1ac7bd44a3aafaff280215450d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Testing: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e459bee769a43c98169be6a119b9cd1",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_77d13ba09fad4b61a6a3f51f54c8910e",
       "value": 1.0
      }
     },
     "9f1fb0e663cb43c8a620d29550cd3497": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9e76ad1ac7bd44a3aafaff280215450d",
        "IPY_MODEL_c784ac001a7543029ca0604669b5d894"
       ],
       "layout": "IPY_MODEL_fadce7364e874bfc9a0209f54d0a4090"
      }
     },
     "c784ac001a7543029ca0604669b5d894": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e6cd5a445d7b4f8594228ad86d220979",
       "placeholder": "​",
       "style": "IPY_MODEL_d0a842ce42e4456981f92ae8e119c05d",
       "value": " 30/30 [00:12&lt;00:00,  2.49it/s]"
      }
     },
     "d0a842ce42e4456981f92ae8e119c05d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e6cd5a445d7b4f8594228ad86d220979": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fadce7364e874bfc9a0209f54d0a4090": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
